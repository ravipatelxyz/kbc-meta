./bin/kbc-cli.py --train data/wn18rr/train.tsv --dev data/wn18rr/dev.tsv --test data/wn18rr/test.tsv -m transe -k 1000 -b 50 -e 100 --F2 0 --N3 0.01 -l 0.1 -I reciprocal -V 3 -o adagrad -c so -q
{'F2': 0.0,
 'N3': 0.01,
 'batch_size': 50,
 'corruption': 'so',
 'dev': 'data/wn18rr/dev.tsv',
 'embedding_size': 1000,
 'epochs': 100,
 'eval_batch_size': None,
 'input_type': 'reciprocal',
 'learning_rate': 0.1,
 'load': None,
 'model': 'transe',
 'optimizer': 'adagrad',
 'quiet': True,
 'save': None,
 'seed': 0,
 'test': 'data/wn18rr/test.tsv',
 'test_i': None,
 'test_ii': None,
 'train': 'data/wn18rr/train.tsv',
 'validate_every': 3}
INFO:kbc-cli.py:Device: cuda
INFO:kbc-cli.py:Model state:
INFO:kbc-cli.py:	entities.weight	torch.Size([40943, 1000])
INFO:kbc-cli.py:	predicates.weight	torch.Size([22, 1000])
Traceback (most recent call last):
  File "./bin/kbc-cli.py", line 266, in <module>
    main(sys.argv[1:])
  File "./bin/kbc-cli.py", line 209, in main
    po_scores = model.forward(xp_batch_emb, None, xo_batch_emb)
  File "/home/pminervi/workspace/kbc-lm/kbc/models/transe.py", line 76, in forward
    _arg2 = arg2.view(1, -1, emb_size).repeat(nb_entities, 1, 1)
RuntimeError: CUDA out of memory. Tried to allocate 7.63 GiB (GPU 0; 10.92 GiB total capacity; 7.93 GiB already allocated; 2.36 GiB free; 7.94 GiB reserved in total by PyTorch)
