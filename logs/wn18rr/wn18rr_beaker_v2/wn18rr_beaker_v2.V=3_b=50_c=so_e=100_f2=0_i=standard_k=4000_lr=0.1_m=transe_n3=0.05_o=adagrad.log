./bin/kbc-cli.py --train data/wn18rr/train.tsv --dev data/wn18rr/dev.tsv --test data/wn18rr/test.tsv -m transe -k 4000 -b 50 -e 100 --F2 0 --N3 0.05 -l 0.1 -I standard -V 3 -o adagrad -c so -q
{'F2': 0.0,
 'N3': 0.05,
 'batch_size': 50,
 'corruption': 'so',
 'dev': 'data/wn18rr/dev.tsv',
 'embedding_size': 4000,
 'epochs': 100,
 'eval_batch_size': None,
 'input_type': 'standard',
 'learning_rate': 0.1,
 'load': None,
 'model': 'transe',
 'optimizer': 'adagrad',
 'quiet': True,
 'save': None,
 'seed': 0,
 'test': 'data/wn18rr/test.tsv',
 'test_i': None,
 'test_ii': None,
 'train': 'data/wn18rr/train.tsv',
 'validate_every': 3}
INFO:kbc-cli.py:Device: cuda
INFO:kbc-cli.py:Model state:
INFO:kbc-cli.py:	entities.weight	torch.Size([40943, 4000])
INFO:kbc-cli.py:	predicates.weight	torch.Size([11, 4000])
Traceback (most recent call last):
  File "./bin/kbc-cli.py", line 266, in <module>
    main(sys.argv[1:])
  File "./bin/kbc-cli.py", line 209, in main
    po_scores = model.forward(xp_batch_emb, None, xo_batch_emb)
  File "/home/pminervi/workspace/kbc-lm/kbc/models/transe.py", line 75, in forward
    _arg1 = ent_emb.view(-1, 1, emb_size).repeat(1, batch_size, 1)
RuntimeError: CUDA out of memory. Tried to allocate 30.51 GiB (GPU 0; 11.91 GiB total capacity; 1.22 GiB already allocated; 10.05 GiB free; 1.23 GiB reserved in total by PyTorch)
